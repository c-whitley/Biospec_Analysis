{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_place = r\"C:\\Users\\Conor\\DataSets\"\n",
    "\n",
    "Breast_DF = pd.read_pickle(file_place + r\"\\Breast_data_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Breast_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the D_Matrix by first encoding the desired categorical labels to numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\scipy\\_lib\\_numpy_compat.py:10: DeprecationWarning: Importing from numpy.testing.nosetester is deprecated since 1.15.0, import from numpy.testing instead.\n",
      "  from numpy.testing.nosetester import import_nose\n",
      "C:\\Users\\Conor\\Anaconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:12: DeprecationWarning: Importing from numpy.testing.decorators is deprecated since numpy 1.15.0, import from numpy.testing instead.\n",
      "  from numpy.testing.decorators import setastest\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "steps = [\n",
    "         (\"Normalise\", Normalizer(norm = \"l1\"))\n",
    "         #(\"RobustScaler\", RobustScaler())\n",
    "        ]\n",
    "\n",
    "pipe  = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Conor\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "C:\\Users\\Conor\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\frame.py:3930: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "import Tissue_Analysis_Tools as TAT\n",
    "\n",
    "PCA_NR_Components = 50\n",
    "\n",
    "dataframe = TAT.process_data(Breast_DF, paraffin = (1340,1490), balance = \"Type\")\n",
    "\n",
    "PCA_reduced = TAT.clean_spectra(dataframe, PCA_NR_Components)\n",
    "\n",
    "values = pipe.fit_transform(PCA_reduced)\n",
    "\n",
    "Breast_DF_P = pd.DataFrame(values, index = dataframe.index, columns = dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "for name, df in Breast_DF_P.groupby(\"Type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "le = LabelEncoder()\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "DATA = Breast_DF_P#.sample(1000)\n",
    "\n",
    "y_label = \"Type\"\n",
    "\n",
    "X = DATA\n",
    "Y = DATA.reset_index()[y_label]\n",
    "Y_b = lb.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.reset_index()[\"Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def sensitivity_Score(y, y_pred, **kwargs):\n",
    "    \n",
    "    assert np.unique(y).size == 2, \"Non_binary sensitivity score\"\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    \n",
    "    return tp/(tp+fn)\n",
    "\n",
    "\n",
    "def specificity_Score(y, y_pred, **kwargs):\n",
    "    \n",
    "    assert np.unique(y).size == 2, \"Non_binary speificity score\"\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    \n",
    "    return tn/(tn+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "param_dist = {'n_estimators': stats.randint(50, 500),\n",
    "              'learning_rate': stats.uniform(0.01, 0.07),\n",
    "              'subsample': stats.uniform(0.3, 0.7),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GroupKFold, GroupShuffleSplit, LeavePGroupsOut, LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{type_: np.unique(DATA.groupby(level = \"Type\").get_group(type_).index.get_level_values(\"Core\")) for type_ in [\"Normal\",\"NAT\",\"Malignant\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, roc_auc_score, precision_score, recall_score, auc, accuracy_score\n",
    "\n",
    "scorers = {\n",
    "    \"Accuracy\": make_scorer(accuracy_score, greater_is_better = True)\n",
    "    ,\"Specificity\": make_scorer(specificity_Score)\n",
    "    ,\"Sensitivity\": make_scorer(sensitivity_Score, greater_is_better = True)\n",
    "    ,\"AUC\": make_scorer(roc_auc_score)\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {\n",
    "                    \"XGB\": ()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    % time\n",
    "\n",
    "    n_Folds = 2\n",
    "\n",
    "    results = dict()\n",
    "\n",
    "    for i, name in enumerate(np.unique(Y)):\n",
    "\n",
    "        # Find out the ratio of positive classes to negative to scale positive weights.\n",
    "        # Allows for compensation of unbalanced classes without throwing away data.\n",
    "\n",
    "        pos_ratio = 1/(np.sum(Y_b[:,i])/Y_b[:,i].shape[0])\n",
    "\n",
    "        clf_xgb = xgb.XGBClassifier(objective = \"binary:logistic\", n_classes = 2, scale_pos_weight = pos_ratio)\n",
    "        #clf_LDA = LinearDiscriminantAnalysis()\n",
    "\n",
    "        clf = RandomizedSearchCV(clf_xgb, param_distributions = param_dist\n",
    "                                 , n_iter = 1, scoring = scorers, refit = \"AUC\"\n",
    "                                 , error_score = 0, verbose = 3\n",
    "                                 , n_jobs = -1, return_train_score = True\n",
    "                                 , cv = GroupKFold(n_Folds).split(X, Y_b[:,i], DATA.reset_index()[\"Core\"])\n",
    "                                )\n",
    "\n",
    "        results[name] = clf.fit(X,Y_b[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "d = datetime.datetime.now().strftime(\"%d/%m/%Y_%H:%M:%S\")\n",
    "\n",
    "output = pd.concat({label: pd.DataFrame(results[label].cv_results_) for label in np.unique(Y)})\n",
    "\n",
    "save_name = r\"C:\\Users\\Conor\\Documents\\Projects\\Biospec_Analysis\\Output\\{}_Balanced_Data_{}\".format(y_label, d)\n",
    "\n",
    "results.to_pickle(os.path.join(save_name, \".pickle\"))\n",
    "output.to_csv(os.path.join(save_name, \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results[\"Malignant\"].cv_results_)\n",
    "\n",
    "plt.clf()\n",
    "threedee = plt.figure().gca(projection='3d')\n",
    "threedee.patch.set_facecolor([1,1,1])\n",
    "\n",
    "threedee.scatter(df[\"param_colsample_bytree\"], df[\"param_learning_rate\"], df[\"mean_test_AUC\"])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
